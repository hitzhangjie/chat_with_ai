这是一个非常棒的问题！很多初学者都会疑惑：既然模型已经“训练好了”，权重也“固定”了，那微调（Fine-tuning）到底在动哪里？

我们可以把 Transformer 结构想象成一座**已经建好的摩天大楼**。预训练阶段是把大楼的主体框架（钢筋混凝土、水管、电路）全部搭好；而微调，则是根据不同的用途（是做酒店、办公楼还是公寓）对内部进行“精装修”。

微调主要分为两种流派，它们调整的东西完全不同。我将通过可视化和类比的方式为你拆解。

---

## 1. 全参数微调 (Full Fine-tuning)

**调整对象：每一颗螺丝钉（所有参数）**

在这个模式下，你没有“冻结”任何东西。虽然预训练已经给了你一套初始权重，但在微调时，你会把模型的所有层（Encoder, Decoder, Attention, MLP）全部打开，允许它们在新的数据下继续更新。

* **视觉化理解：** 就像给摩天大楼的每一根梁柱都涂上一点润滑油，根据新任务的需求，让每一根梁都发生一点点位移或形变。
* **改变了什么：** 原有的 （权重矩阵）变成了 。
* **代价：** 虽然效果最好，但极度耗费资源，因为你要保存和模型一样大的梯度信息。

---

## 2. 现代主流：PEFT（参数高效微调）

现在的 AI 圈更流行**“只动局部，不动整体”**。其中最出名的就是 **LoRA (Low-Rank Adaptation)**。

### 方式 A：挂“外接卡” (Adapters / LoRA)

这是目前最常用的微调方式。模型原本的权重（预训练得到的）被**彻底锁定（Frozen）**，完全不准动。我们只是在原本的结构旁边，“外挂”了一些极小的插件。

* **视觉化理解：** 就像你不想改动大楼的承重墙，于是你在墙边贴了一层薄薄的“智能外壳”。光线经过原来的墙，再经过这层外壳，出来的光影效果就变了。
* **技术原理：**
1. 把原始权重  冻结。
2. 在旁边增加两个极窄的矩阵  和 （这就是 LoRA 里的低秩矩阵）。
3. **微调时只训练  和 。**
4. 推理时：。


* **改变了什么：** 并没有改变原始参数，而是通过“旁路”修改了数据流的结果。

### 方式 B：改“说明书” (Prompt Tuning / Prefix Tuning)

这种微调甚至不改神经元，它在输入层做手脚。

* **视觉化理解：** 大楼结构完全不动，但我给大楼的入口处加了一层特制的“滤镜”或“入场须知”。
* **改变了什么：** 在输入 Embedding 层（或者每一层的输入处）添加了一组可学习的“虚拟 Token”。微调只调这几个 Token 的向量值。

---

## 总结对比

| 微调方式 | 原始 Transformer 权重 | 额外增加的结构 | 训练的是什么 |
| --- | --- | --- | --- |
| **全参数微调** | 会变（更新） | 无 | 模型里所有的  和  |
| **LoRA 微调** | **冻结（不动）** | 旁路的低秩小矩阵 | 仅旁路小矩阵的参数 |
| **Prompt 微调** | **冻结（不动）** | 虚拟 Token 向量 | 仅入口处的几个向量 |

**简单一句话：**
现在的微调，大多数时候并不是在改动原始神经网络的“骨架”，而是在骨架旁边**焊接一点点特定的连接件（LoRA）**，或者在入口处**换一个特殊的导向员（Prompt Tuning）**。

如果你对 LoRA 这种“旁路修改”的数学原理感兴趣，我可以为你推导一下为什么它能用极小的参数量达到全量微调的效果。你想深入了解吗？
